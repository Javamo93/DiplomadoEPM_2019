{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "p37",
      "language": "python",
      "name": "p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Modulo 3 (20 - TALLER Embeddings).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sOpYoJlEITD",
        "colab_type": "code",
        "outputId": "aa822c43-af0a-46e5-e088-bae97f5c9f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/jdariasl/DiplomadoEPM_2019/master/Modulo3/init.py\n",
        "from init import init; init(force_download=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replicating local resources\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_9bXnOfEITK",
        "colab_type": "code",
        "outputId": "9eaa2743-aa08-40eb-cb99-8c3b7bd94b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print (\"setting tensorflow version in colab\")\n",
        "    %tensorflow_version 2.x\n",
        "    %load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting tensorflow version in colab\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpN2yk-GSrb5",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings for sentiment analysis on tweets data\n",
        "\n",
        "Understand the following Kaggle competition\n",
        "\n",
        "- https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
        "\n",
        "And the solution proposed in this Notebook\n",
        "\n",
        "- https://www.kaggle.com/bertcarremans/deep-learning-for-sentiment-analysist\n",
        "\n",
        "observe this solution builds its own dictionary of words and creates a one-hot encoding that is fed directly to the model.\n",
        "\n",
        "# Part 1\n",
        "\n",
        "In this lab you will have to:\n",
        "\n",
        "- **Upload** the `Tweets.csv.zip` file to this notebook execution environment.\n",
        "- **Replicate** the solution above\n",
        "- **Substitute** the one-hot encoding input to the model with a 500 components embedding with the corresponding Keras layer\n",
        "\n",
        "You should get similar accuracy to that in the Kaggle notebook but with faster overfitting, suggesting your model will probably benefit faster from additional training data.\n",
        "\n",
        "Use the next line to unzip the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7jsysJoOPLq",
        "colab_type": "code",
        "outputId": "6865ecad-f695-4019-9b9a-1ef26ed0d0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip Tweets.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Tweets.csv.zip\n",
            "  inflating: Tweets.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeuqASNgSufb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment for solution\n",
        "#k = b'0a66726f6d2074656e736f72666c6f772e6b6572617320696d706f72742070726570726f63657373696e670a58585f747261696e5f736571203d2070726570726f63657373696e672e73657175656e63652e7061645f73657175656e63657328585f747261696e5f7365712c206d61786c656e3d6d61786c656e290a58585f746573745f736571203d2070726570726f63657373696e672e73657175656e63652e7061645f73657175656e63657328585f746573745f7365712c206d61786c656e3d6d61786c656e290a58585f747261696e5f726573742c2058585f76616c69642c20795f747261696e5f726573742c20795f76616c6964203d20747261696e5f746573745f73706c69742858585f747261696e5f7365712c20795f747261696e5f6f682c20746573745f73697a653d302e312c2072616e646f6d5f73746174653d3337290a0a626173655f6d6f64656c203d206d6f64656c732e53657175656e7469616c28290a656d62656464696e675f6c61796572203d206c61796572732e456d62656464696e67284e425f574f5244532c203130302c20696e7075745f6c656e6774683d6d61786c656e290a626173655f6d6f64656c2e61646428656d62656464696e675f6c61796572290a626173655f6d6f64656c2e616464286c61796572732e466c617474656e2829290a626173655f6d6f64656c2e616464286c61796572732e44656e73652836342c2061637469766174696f6e3d2772656c75272c20696e7075745f73686170653d284e425f574f5244532c2929290a626173655f6d6f64656c2e616464286c61796572732e44656e73652836342c2061637469766174696f6e3d2772656c752729290a626173655f6d6f64656c2e616464286c61796572732e44656e736528332c2061637469766174696f6e3d27736f66746d61782729290a626173655f6d6f64656c2e73756d6d61727928290a626173655f6d6f64656c2e636f6d70696c65286f7074696d697a65723d27726d7370726f70270a20202020202020202020202020202c206c6f73733d2763617465676f726963616c5f63726f7373656e74726f7079270a20202020202020202020202020202c206d6574726963733d5b276163637572616379275d290a0a626173655f686973746f7279203d20626173655f6d6f64656c2e6669742858585f747261696e5f726573742c20795f747261696e5f726573742c0a202020202020202020202020202020202020202065706f6368733d4e425f53544152545f45504f4348532c2062617463685f73697a653d42415443485f53495a452c0a202020202020202020202020202020202020202076616c69646174696f6e5f646174613d2858585f76616c69642c20795f76616c696429290a0a6576616c5f6d657472696328626173655f686973746f72792c202761636375726163792729'\n",
        "#import binascii; print(binascii.a2b_hex(k).decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UjGDAjiXcgh",
        "colab_type": "text"
      },
      "source": [
        "# Part 2\n",
        "\n",
        "Use the embeddings of the NNLM model avaiable through [TensorHub](https://www.tensorflow.org/hub), which can be found as the example in its home page, or [here](https://tfhub.dev/google/collections/nnlm/1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDUYSApYWc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment for solution\n",
        "#k = b'0a696d706f72742074656e736f72666c6f772061732074660a696d706f72742074656e736f72666c6f775f687562206173206875620a0a6d6f64756c655f75726c203d202268747470733a2f2f74666875622e6465762f676f6f676c652f6e6e6c6d2d656e2d64696d3132382f32220a656d626564203d206875622e4b657261734c61796572286d6f64756c655f75726c290a58655f747261696e203d20656d62656428585f747261696e2e76616c756573292e6e756d707928290a58655f7465737420203d20656d62656428585f746573742e76616c756573292e6e756d707928290a58655f747261696e5f726573742c2058655f76616c69642c20795f747261696e5f726573742c20795f76616c6964203d20747261696e5f746573745f73706c69742858655f747261696e2c20795f747261696e5f6f682c20746573745f73697a653d302e312c2072616e646f6d5f73746174653d3337290a0a626173655f6d6f64656c203d206d6f64656c732e53657175656e7469616c28290a626173655f6d6f64656c2e616464286c61796572732e44656e7365283132382c2061637469766174696f6e3d2772656c75272c20696e7075745f73686170653d283132382c2929290a626173655f6d6f64656c2e616464286c61796572732e44656e73652836342c2061637469766174696f6e3d2772656c752729290a626173655f6d6f64656c2e616464286c61796572732e44726f706f757428302e3429290a626173655f6d6f64656c2e616464286c61796572732e44656e736528332c2061637469766174696f6e3d27736f66746d61782729290a626173655f6d6f64656c2e73756d6d61727928290a626173655f6d6f64656c2e636f6d70696c65286f7074696d697a65723d27726d7370726f70272c206c6f73733d2763617465676f726963616c5f63726f7373656e74726f7079272c206d6574726963733d5b276163637572616379275d290a0a626173655f686973746f7279203d20626173655f6d6f64656c2e6669742858655f747261696e5f726573742c20795f747261696e5f726573742c0a202020202020202020202020202020202020202065706f6368733d4e425f53544152545f45504f4348532c2062617463685f73697a653d42415443485f53495a452c0a202020202020202020202020202020202020202076616c69646174696f6e5f646174613d2858655f76616c69642c20795f76616c696429290a0a6576616c5f6d657472696328626173655f686973746f72792c2027616363757261637927290a'\n",
        "#import binascii; print(binascii.a2b_hex(k).decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb6_5H6qYUwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}